@page "/video"
@using KristofferStrube.Blazor.MediaCaptureStreams.Exceptions;
@using KristofferStrube.Blazor.WebIDL.Exceptions;
@implements IAsyncDisposable
@inject IMediaDevicesService MediaDevicesService
@inject IJSRuntime JSRuntime

<PageTitle>Media Capture and Streams - Video Capture</PageTitle>

<h2>Video Capture</h2>

<p>Here we open a video track with the constraint of having a 16:9 aspect ratio and show it in a <code>video</code> tag.</p>
<p>After it has been opened we make it possible to choose other devices that are of the kind <code>videoinput</code>.</p>
<p>We can also adjust the frame rate and potentially set it outside the range of the capabilities of your device which will throw an <code>OverconstrainedErrorException</code> that we can catch.</p>

@if (error is { } errorMessage)
{
    <p style="color: red;">@errorMessage</p>
}
@if (videoStreamTrack is null)
{
    <button class="btn btn-primary" @onclick="OpenVideo">Load Camera</button>
}
else
{
    @if (videoOptions.Count > 0)
    {
        <label for="videoSource">Video Source</label>
        <select id="videoSource" @bind=selectedVideoSource @bind:after="SelectDevice">
            @foreach (var option in videoOptions)
            {
                <option value="@option.id" selected="@(option.id == selectedVideoSource)">@option.label</option>
            }
        </select>
        <br />
        <label for="frameRate">Frame Rate (Current Camera Capabilites are @minimalFrameRate - @maximumFrameRate)</label>
        <input id="frameRate" type="number" step="1" @bind="frameRate" @bind:after="ChangeFrameRate" />
    }
    <video @ref="videoElement" width="100%" height="400" autoplay controls></video>
}

@code {
    private MediaDevices? mediaDevices = default;
    private MediaStreamTrack? videoStreamTrack;
    private string? error;
    private ElementReference videoElement;
    private List<(string label, string id)> videoOptions = new();
    private string? selectedVideoSource;
    private string? shownVideoSource;
    private double? frameRate;
    private double minimalFrameRate;
    private double maximumFrameRate;

    async Task OpenVideo()
    {
        try
        {
            if (mediaDevices is null)
                mediaDevices = await MediaDevicesService.GetMediaDevicesAsync();

            await SelectDevice();
            var deviceInfos = await mediaDevices.EnumerateDevicesAsync();
            videoOptions.Clear();
            foreach (var device in deviceInfos)
            {
                if (await device.GetKindAsync() is MediaDeviceKind.VideoInput)
                {
                    videoOptions.Add((await device.GetLabelAsync(), await device.GetDeviceIdAsync()));
                }
            }
            error = null;
        }
        catch (WebIDLException ex)
        {
            error = $"{ex.GetType().Name}: {ex.Message}";
            await StopVideoTrack();
        }
        catch (Exception ex)
        {
            throw;
            // await StopVideoTrack();
        }
    }

    async Task ChangeFrameRate()
    {
        try
        {
            var mediaTrackConstraints = new MediaTrackConstraints()
                {
                    FrameRate = frameRate is { } setFrameRate ? new ConstrainDoubleRange() { Exact = setFrameRate } : frameRate
                };
            if (selectedVideoSource is not null)
            {
                mediaTrackConstraints.DeviceId = new ConstrainDOMStringParameters() { Exact = selectedVideoSource };
            }
            await videoStreamTrack.ApplyContraintsAsync(mediaTrackConstraints);
        }
        catch (OverconstrainedErrorException ex)
        {
            error = $"The following constraint was overconstrained: {ex.Constraint}";
            await StopVideoTrack();
        }
        catch (WebIDLException ex)
        {
            error = $"{ex.GetType().Name}: {ex.Message}";
            await StopVideoTrack();
        }
        catch (Exception)
        {
            throw;
        }
    }

    async Task SelectDevice()
    {
        if (selectedVideoSource != null && shownVideoSource == selectedVideoSource)
            return; // They picked the same device

        var mediaTrackConstraints = new MediaTrackConstraints();
        if (selectedVideoSource is not null)
        {
            mediaTrackConstraints.DeviceId = new ConstrainDOMStringParameters() { Exact = selectedVideoSource };
        }

        await using var mediaStream = await mediaDevices!.GetUserMediaAsync(new MediaStreamConstraints() { Video = mediaTrackConstraints });
        var videoTracks = await mediaStream.GetVideoTracksAsync();
        videoStreamTrack = videoTracks.FirstOrDefault();
        foreach (var unusedTrack in videoTracks.Skip(1))
        {
            await unusedTrack.DisposeAsync();
        }
        if (videoStreamTrack is not null)
        {
            var capabilities = await videoStreamTrack.GetCapabilitiesAsync();
            minimalFrameRate = capabilities.FrameRate?.Min ?? 0;
            maximumFrameRate = capabilities.FrameRate?.Max ?? 0;
            frameRate = (maximumFrameRate + minimalFrameRate) / 2.0;
            selectedVideoSource = capabilities.DeviceId;
            shownVideoSource = selectedVideoSource;
        }

        StateHasChanged();
        // We don't have a wrapper for HtmlMediaElement's yet so we use simple JSInterop for this part.
        await using var htmlMediaElement = await JSRuntime.InvokeAsync<IJSObjectReference>("getReference", videoElement);
        await JSRuntime.InvokeVoidAsync("setAttribute", htmlMediaElement, "srcObject", mediaStream.JSReference);
    }

    async Task StopVideoTrack()
    {
        if (videoStreamTrack is not null)
        {
            await videoStreamTrack.StopAsync();
        }
        videoStreamTrack = null;
        frameRate = null;
        if (mediaDevices is not null)
            await mediaDevices.DisposeAsync();
        mediaDevices = null;
        shownVideoSource = null;
        selectedVideoSource = null;
    }

    public async ValueTask DisposeAsync()
    {
        await StopVideoTrack();
    }
}